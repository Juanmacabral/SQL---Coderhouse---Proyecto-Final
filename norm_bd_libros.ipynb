{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a848a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac2db52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\juanm\\\\OneDrive\\\\Escritorio\\\\pythonProject\\\\SQL---Coderhouse---Proyecto-Final\\\\csvs\\\\originales')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3993f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv('books_data.csv')\n",
    "ratings = pd.read_csv('Books_rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880724af",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Datos originilales\n",
    "Books (212404,10)\n",
    "ratings(30000000,10)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35ba5244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aca va el proceso de normalizacion de las tablas\n",
    "#Eliminar columnas\n",
    "books = books.drop(columns=['image','previewLink','infoLink','ratingsCount', 'description'])\n",
    "ratings = ratings.drop(columns=['review/helpfulness','review/time', 'review/summary', 'review/text'])\n",
    "#merge de ambas columnas, a fin de eliminar valores y no dejar datos huerfanos\n",
    "merged_df = pd.merge(books,ratings, on='Title')\n",
    "merged_df = merged_df.dropna(subset=['Title']) #elimino filas donde 'Title' es NaN value\n",
    "merged_df = merged_df.dropna(subset=['User_id', 'profileName'], how='all') #Elimino Nan Values relacionado con usuarios\n",
    "merged_df = merged_df.dropna(subset=['profileName']) #Elimino Nan Values relacionado con usuarios\n",
    "merged_df = merged_df.dropna(subset=['publisher', 'publishedDate', 'categories']) #elimino mas Nan values\n",
    "merged_df = merged_df.dropna(subset=['authors'])#elimino mas Nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa956b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'authors', 'publisher', 'publishedDate', 'categories', 'Id',\n",
       "       'Price', 'User_id', 'profileName', 'review/score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d907383e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'De esta manera, queda un dataset con 306450 filas por 11 columnas\\nal cual hay que dividir en 5 tablas'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''CASO COLUMNA PRICE\n",
    "Existe una cantidad enorme de Nan Values, pero algunos son recuperables, ya que segun el nro de ID, algunos books tiene precio,\n",
    "entonces,procedo a completar esos valores que se pueden rellenar'''\n",
    "\n",
    "# Calcular el valor promedio de Prices para cada book_id\n",
    "avg_prices = merged_df.groupby('Id')['Price'].mean()\n",
    "\n",
    "# Rellenar los valores NaN en Prices con el valor promedio para el book_id correspondiente\n",
    "merged_df['Price'] = merged_df.apply(lambda row: avg_prices[row['Id']] if pd.isna(row['Price']) else row['Price'], axis=1)\n",
    "\n",
    "#los prices que siguen quedando como Nan, se descartan\n",
    "merged_df = merged_df.dropna(subset=['Price'])#elimino mas Nan values\n",
    "\n",
    "'''De esta manera, queda un dataset con 306450 filas por 11 columnas\n",
    "al cual hay que dividir en 5 tablas'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4890865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genero nros de id desde 1\n",
    "def add_factorize_id_column(df, column_name, new_column_name):\n",
    "    df[new_column_name] = pd.factorize(df[column_name])[0] + 1\n",
    "    return df\n",
    "\n",
    "merged_df = add_factorize_id_column(merged_df, 'Title', 'id_book')\n",
    "merged_df = add_factorize_id_column(merged_df, 'User_id', 'id_user')\n",
    "merged_df = add_factorize_id_column(merged_df, 'categories', 'id_categories')\n",
    "\n",
    "#Elimino mas columnas que no sirven\n",
    "merged_df = merged_df.drop(columns=['Id', 'User_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43740ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpio las columnas de caracteres no deseados\n",
    "def clean_column(col):\n",
    "    col = col.str.replace('\"', '').str.replace(\"'\", '')\n",
    "    col = col.str.strip('[]')\n",
    "    col = col.str.replace('\"', '').str.replace(\"'\", '')\n",
    "    return col\n",
    "\n",
    "merged_df[['profileName', 'authors', 'categories']] = merged_df[['profileName', 'authors', 'categories']].apply(clean_column)\n",
    "\n",
    "# Extrae solo el año de la columna 'publishedDate'\n",
    "merged_df['publishedDate'] = merged_df['publishedDate'].str.extract(r'\\b(\\d{4})\\b')\n",
    "\n",
    "#cambio el nombre de las columnas\n",
    "merged_df = merged_df.rename(columns={'Title': 'title', 'publishedDate': 'published_year', 'Price': 'price',\n",
    "                                      'profileName': 'profile_name', 'review/score': 'score'})\n",
    "\n",
    "#reinicio el indice\n",
    "merged_df = merged_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cced05c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar merged_df en 5 tablas diferentes\n",
    "def create_table(df, cols, drop_duplicates=None):\n",
    "    table = df[cols]\n",
    "    if drop_duplicates:\n",
    "        table = table.drop_duplicates(subset=drop_duplicates)\n",
    "    table = table.reset_index(drop=True)\n",
    "    return table\n",
    "\n",
    "books = create_table(merged_df, ['id_book', 'title', 'authors', 'publisher', 'published_year', 'id_categories'], 'id_book')\n",
    "ratings = create_table(merged_df, ['id_user', 'id_book', 'score'])\n",
    "categories = create_table(merged_df, ['id_categories', 'categories'], 'id_categories')\n",
    "prices = create_table(merged_df, ['id_book', 'price'], 'id_book')\n",
    "users = create_table(merged_df, ['id_user', 'profile_name'], 'id_user')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3868ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ultimos arreglos en tabla books:\n",
    "#quedaron 2 filas con valores null\n",
    "books = books.dropna()\n",
    "books['published_year'] = books['published_year'].astype(int) #paso published_year de object a int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b75b4bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_book</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>publisher</th>\n",
       "      <th>published_year</th>\n",
       "      <th>id_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Whispers of the Wicked Saints</td>\n",
       "      <td>Veronica Haddon</td>\n",
       "      <td>iUniverse</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The Church of Christ: A Biblical Ecclesiology ...</td>\n",
       "      <td>Everett Ferguson</td>\n",
       "      <td>Wm. B. Eerdmans Publishing</td>\n",
       "      <td>1996</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Saint Hyacinth of Poland</td>\n",
       "      <td>Mary Fabyan Windeatt</td>\n",
       "      <td>Tan Books &amp; Pub</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Vector Quantization and Signal Compression (Th...</td>\n",
       "      <td>Allen Gersho, Robert M. Gray</td>\n",
       "      <td>Springer Science &amp; Business Media</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Ultimate Guide to Law School Admission: In...</td>\n",
       "      <td>Fiona Cownie</td>\n",
       "      <td>Bloomsbury Publishing</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33908</th>\n",
       "      <td>33909</td>\n",
       "      <td>Governance Of Science (Issues in Society)</td>\n",
       "      <td>Fuller, Steve</td>\n",
       "      <td>McGraw-Hill Education (UK)</td>\n",
       "      <td>1999</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33909</th>\n",
       "      <td>33910</td>\n",
       "      <td>Is Your Retirement Heading in the Right Direct...</td>\n",
       "      <td>Steven Casto</td>\n",
       "      <td>Strategic Wealth Solutions, LLC</td>\n",
       "      <td>2005</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33910</th>\n",
       "      <td>33911</td>\n",
       "      <td>The Awakening and Selected Stories (Modern Lib...</td>\n",
       "      <td>Kate Chopin</td>\n",
       "      <td>Library of Alexandria</td>\n",
       "      <td>2003</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33911</th>\n",
       "      <td>33912</td>\n",
       "      <td>The Orphan Of Ellis Island (Time Travel Advent...</td>\n",
       "      <td>Elvira Woodruff</td>\n",
       "      <td>Scholastic Paperbacks</td>\n",
       "      <td>2000</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33912</th>\n",
       "      <td>33913</td>\n",
       "      <td>The Autograph Man</td>\n",
       "      <td>Zadie Smith</td>\n",
       "      <td>Vintage</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33911 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_book                                              title   \n",
       "0            1                      Whispers of the Wicked Saints  \\\n",
       "1            2  The Church of Christ: A Biblical Ecclesiology ...   \n",
       "2            3                           Saint Hyacinth of Poland   \n",
       "3            4  Vector Quantization and Signal Compression (Th...   \n",
       "4            5  The Ultimate Guide to Law School Admission: In...   \n",
       "...        ...                                                ...   \n",
       "33908    33909          Governance Of Science (Issues in Society)   \n",
       "33909    33910  Is Your Retirement Heading in the Right Direct...   \n",
       "33910    33911  The Awakening and Selected Stories (Modern Lib...   \n",
       "33911    33912  The Orphan Of Ellis Island (Time Travel Advent...   \n",
       "33912    33913                                  The Autograph Man   \n",
       "\n",
       "                            authors                          publisher   \n",
       "0                   Veronica Haddon                          iUniverse  \\\n",
       "1                  Everett Ferguson         Wm. B. Eerdmans Publishing   \n",
       "2              Mary Fabyan Windeatt                    Tan Books & Pub   \n",
       "3      Allen Gersho, Robert M. Gray  Springer Science & Business Media   \n",
       "4                      Fiona Cownie              Bloomsbury Publishing   \n",
       "...                             ...                                ...   \n",
       "33908                 Fuller, Steve         McGraw-Hill Education (UK)   \n",
       "33909                  Steven Casto    Strategic Wealth Solutions, LLC   \n",
       "33910                   Kate Chopin              Library of Alexandria   \n",
       "33911               Elvira Woodruff              Scholastic Paperbacks   \n",
       "33912                   Zadie Smith                            Vintage   \n",
       "\n",
       "       published_year  id_categories  \n",
       "0                2005              1  \n",
       "1                1996              2  \n",
       "2                2009              3  \n",
       "3                2012              4  \n",
       "4                2010              5  \n",
       "...               ...            ...  \n",
       "33908            1999             22  \n",
       "33909            2005             16  \n",
       "33910            2003            517  \n",
       "33911            2000             26  \n",
       "33912            2003              1  \n",
       "\n",
       "[33911 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67e1351f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "books:  (33911, 6)\n",
      "reviews:  (306450, 3)\n",
      "categories:  (942, 2)\n",
      "prices:  (33913, 2)\n",
      "users:  (236353, 2)\n"
     ]
    }
   ],
   "source": [
    "#Dimensiones de las tablas una vez finalizado el proceso\n",
    "print('books: ', books.shape)\n",
    "print('reviews: ', reviews.shape)\n",
    "print('categories: ', categories.shape)\n",
    "print('prices: ', prices.shape)\n",
    "print('users: ', users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "180584a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title             0\n",
      "authors           0\n",
      "publisher         0\n",
      "published_year    8\n",
      "categories        0\n",
      "price             0\n",
      "profile_name      0\n",
      "score             0\n",
      "id_book           0\n",
      "id_user           0\n",
      "id_categories     0\n",
      "dtype: int64\n",
      "----------------\n",
      "title              33913\n",
      "authors            29984\n",
      "publisher           5644\n",
      "published_year       124\n",
      "categories           942\n",
      "price               5224\n",
      "profile_name      213344\n",
      "score                  5\n",
      "id_book            33913\n",
      "id_user           236353\n",
      "id_categories        942\n",
      "dtype: int64\n",
      "----------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Price'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\OneDrive\\Escritorio\\Python\\SQL---Coderhouse---Proyecto-Final\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\OneDrive\\Escritorio\\Python\\SQL---Coderhouse---Proyecto-Final\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\OneDrive\\Escritorio\\Python\\SQL---Coderhouse---Proyecto-Final\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Price'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(merged_df\u001b[38;5;241m.\u001b[39mnunique())\u001b[38;5;66;03m#Ver cuantos valores unicos hay por columna\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmerged_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe())\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(merged_df\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\OneDrive\\Escritorio\\Python\\SQL---Coderhouse---Proyecto-Final\\lib\\site-packages\\pandas\\core\\frame.py:3760\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3759\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3760\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3762\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\OneDrive\\Escritorio\\Python\\SQL---Coderhouse---Proyecto-Final\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Price'"
     ]
    }
   ],
   "source": [
    "#herramientas de consulta:\n",
    "null_counts = merged_df.isnull().sum()\n",
    "print(null_counts) #ver cuantos Nan values hay en cada columna\n",
    "print('----------------')\n",
    "print(merged_df.nunique())#Ver cuantos valores unicos hay por columna\n",
    "print('----------------')\n",
    "print(merged_df['Price'].describe())\n",
    "print('----------------')\n",
    "print(merged_df.shape)\n",
    "print('----------------')\n",
    "\n",
    "'''Use este codigo para ver cuantos prices pueden completarse con valores ya existentes\n",
    "def has_mixed_prices(group):\n",
    "    has_nan = np.isnan(group['Price']).any()\n",
    "    has_number = np.isfinite(group['Price']).any()\n",
    "    return has_nan and has_number\n",
    "\n",
    "has_mixed = merged_df.groupby('id_book').apply(has_mixed_prices)\n",
    "book_ids_with_mixed_prices = has_mixed[has_mixed].index.to_list()\n",
    "print(\"Book IDs con precios mixtos:\", book_ids_with_mixed_prices)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "540199f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\juanm\\\\OneDrive\\\\Escritorio\\\\pythonProject\\\\SQL---Coderhouse---Proyecto-Final\\\\csvs\\\\normalizados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af73b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "books.to_csv('books.csv', index=False)\n",
    "ratings.to_csv('ratings.csv', index=False)\n",
    "categories.to_csv('categories.csv', index=False)\n",
    "prices.to_csv('prices.csv', index=False)\n",
    "users.to_csv('users.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
